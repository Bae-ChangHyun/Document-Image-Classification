{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer,AutoImageProcessor\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# pip uninstall charset-normalizer\n",
    "# pip install charset-normalizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import fastdup\n",
    "from augraphy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_num):\n",
    "    torch.manual_seed(seed_num)\n",
    "    torch.cuda.manual_seed(seed_num)\n",
    "    torch.cuda.manual_seed_all(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    random.seed(seed_num)\n",
    "random_seed(624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if len(img.shape) < 3 or img.shape[2] != 3:\n",
    "            img = np.stack([img] * 3, axis=-1)\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target,name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(origin_img_path,origin_csv,aug_img_path,aug_csv_path,transform,pipeline,N_ALBUM,N_AUGRAPHY):\n",
    "    \n",
    "    os.makedirs(aug_img_path, exist_ok=True)\n",
    "    aug_data=pd.DataFrame(columns=['ID','target'])\n",
    "    \n",
    "    for i in tqdm(range(len(origin_csv))):\n",
    "        image_id=origin_csv.iloc[i]['ID']\n",
    "        target=origin_csv.iloc[i]['target'] # 원본 이미지의 라벨값\n",
    "        alpha,save_count = 0, 0\n",
    "        image = cv2.imread(f'{origin_img_path}{image_id}')\n",
    "            \n",
    "        if(target in [3,4,7]):alpha=10\n",
    "        elif(target==14):alpha=20\n",
    "        \n",
    "        # Augraphy\n",
    "        # https://github.com/sparkfish/augraphy\n",
    "        for i in range(N_AUGRAPHY+alpha):\n",
    "            transformed_image = pipeline(image)\n",
    "            #transformed_image = np.clip(transformed_image, 0, 255).astype(np.uint8) # Convert to uint8\n",
    "            save_count += 1\n",
    "            cv2.imwrite(f'{aug_img_path}{image_id[:-4]}_{save_count}.jpg', transformed_image)\n",
    "        \n",
    "        # Albumentation\n",
    "        # https://github.com/albumentations-team/albumentations\n",
    "        for i in range(N_ALBUM):\n",
    "            transformed_image = transform(image=image)['image']\n",
    "            #transformed_image = np.clip(transformed_image, 0, 255).astype(np.uint8) # Convert to uint8\n",
    "            save_count += 1\n",
    "            cv2.imwrite(f'{aug_img_path}{image_id[:-4]}_{save_count}.jpg', transformed_image)\n",
    "            \n",
    "        cv2.imwrite(f'{aug_img_path}{image_id}', image) # 원본이미지 재저장\n",
    "        \n",
    "        length=N_ALBUM+N_AUGRAPHY+alpha+1\n",
    "        tmp = pd.DataFrame({'ID': [f'{image_id[:-4]}_{i}.jpg' for i in range(1,length)]})\n",
    "        tmp['target'] = target\n",
    "        aug_data = pd.concat([aug_data, tmp], ignore_index=True) \n",
    "        aug_data = pd.concat([aug_data, pd.DataFrame({'ID': f'{image_id}', 'target': [target]})], ignore_index=True) \n",
    "        \n",
    "    aug_data.to_csv(aug_csv_path,index=False)    \n",
    "        \n",
    "    return aug_data\n",
    "\n",
    "# def makedf(origin_csv,aug_csv_path,N_ALBUM,N_AUGRAPHY):\n",
    "#     length=N_ALBUM+N_AUGRAPHY+1\n",
    "    \n",
    "#     aug_data=pd.DataFrame(columns=['ID','target'])\n",
    "\n",
    "#     for i in tqdm(range(len(origin_csv))):\n",
    "#         image_id=origin_csv.iloc[i]['ID'] # 원본 이미지 파일이름\n",
    "#         target=origin_csv.iloc[i]['target'] # 원본 이미지의 라벨값\n",
    "        \n",
    "#         tmp = pd.DataFrame({'ID': [f'{image_id[:-4]}_{i}.jpg' for i in range(1,length)]})\n",
    "#         tmp['target'] = target\n",
    "#         aug_data = pd.concat([aug_data, tmp], ignore_index=True) \n",
    "#         aug_data = pd.concat([aug_data, pd.DataFrame({'ID': f'{image_id}', 'target': [target]})], ignore_index=True) \n",
    "        \n",
    "#     print(\"Origin data length: \",len(aug_data)//length)\n",
    "#     print(\"Augment data length: \", len(aug_data)-len(aug_data)//length)\n",
    "    \n",
    "#     aug_data.to_csv(aug_csv_path,index=False)\n",
    "     \n",
    "#     return aug_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ink_phase = AugmentationSequence([OneOf(\n",
    "        [\n",
    "            InkShifter(\n",
    "                text_shift_scale_range=(18, 27),\n",
    "                text_shift_factor_range=(1, 4),\n",
    "                text_fade_range=(0, 2),\n",
    "                blur_kernel_size=(5, 5),\n",
    "                blur_sigma=0,\n",
    "                noise_type=\"random\",\n",
    "            ),\n",
    "            BleedThrough(\n",
    "                intensity_range=(0.1, 0.3),\n",
    "                color_range=(32, 224),\n",
    "                ksize=(17, 17),\n",
    "                sigmaX=1,\n",
    "                alpha=random.uniform(0.1, 0.2),\n",
    "                offsets=(10, 20),\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    ),])\n",
    "\n",
    "paper_phase = AugmentationSequence([OneOf(\n",
    "    [\n",
    "\tAugmentationSequence(\n",
    "     [\n",
    "\t    NoiseTexturize(sigma_range=(3, 10), turbulence_range=(2, 5), texture_width_range=(300, 500), texture_height_range=(300, 500), p=1),\n",
    "\t    BrightnessTexturize(texturize_range=(0.9, 0.99), deviation=0.03, p=1),\n",
    "    ]),\n",
    "\tAugmentationSequence(\n",
    "     [\n",
    "\t    BrightnessTexturize(texturize_range=(0.9, 0.99), deviation=0.03, p=1),\n",
    "\t    NoiseTexturize(sigma_range=(3, 10), turbulence_range=(2, 5), texture_width_range=(300, 500), texture_height_range=(300, 500), p=1),\n",
    "    ])\n",
    "    ], p=0.5),\n",
    "])\n",
    "\n",
    "post_phase = AugmentationSequence([\n",
    "\tOneOf([\n",
    "\tGlitchEffect(glitch_direction=random, glitch_number_range=(8, 16), glitch_size_range=(5, 50), glitch_offset_range=(10, 50), p=1),\n",
    "\tColorShift(color_shift_offset_x_range=(3, 5), color_shift_offset_y_range=(3, 5), color_shift_iterations=(2, 3), color_shift_brightness_range=(0.9, 1.1), color_shift_gaussian_kernel_range=(3, 3), p=1)\n",
    "], p=0.2),\n",
    "\tOneOf([\n",
    "\tDirtyDrum(line_width_range=(1, 6), line_concentration=0.10080769473847595, direction=0, noise_intensity=0.7786602736626571, noise_value=(64, 224), ksize=(7, 7), sigmaX=0,p=0.2),\n",
    "\tDirtyRollers(line_width_range=(2, 32), scanline_type=0, numba_jit=1, p=1)\n",
    "], p=0.2),\n",
    "\tOneOf([\n",
    "\tLightingGradient(light_position=None, direction=None, max_brightness=255, min_brightness=0, mode='gaussian', linear_decay_rate=None, transparency=None, numba_jit=1, p=1),\n",
    "\tBrightness(brightness_range=(0.9, 1.1), min_brightness=0, min_brightness_value=(120, 150), numba_jit=1, p=1),\n",
    "\tGamma(gamma_range=(0.9, 1.1), p=1)\n",
    "], p=0.2),\n",
    "\tOneOf([\n",
    "\tSubtleNoise(subtle_range=6, p=1),\n",
    "\tJpeg(quality_range=(25, 95), p=1)\n",
    "], p=0.2),\n",
    "\tOneOf([\n",
    "\tBadPhotoCopy(noise_mask=None, noise_type=-1, noise_side=random, noise_iteration=(1, 2), noise_size=(1, 3), noise_value=[128, 196], noise_sparsity=[0.3, 0.6], noise_concentration=[0.1, 0.6], blur_noise=True, blur_noise_kernel=(7, 7), wave_pattern=False, edge_effect=True, numba_jit=1, p=1),\n",
    "\tShadowCast(shadow_side=random, shadow_vertices_range=(1, 20), shadow_width_range=(0.3, 0.8), shadow_height_range=(0.3, 0.8), shadow_color=(0, 0, 0), shadow_opacity_range=(0.2, 0.9), shadow_iterations_range=(1, 2), shadow_blur_kernel_range=(101, 301), p=1)\n",
    "], p=0.2),\n",
    "\tFolding(fold_x=None, fold_deviation=(0, 0), fold_count=2, fold_noise=0.01, fold_angle_range=(-360, 360), gradient_width=(0.1, 0.2), gradient_height=(0.01, 0.02), backdrop_color=(0, 0, 0), p=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AugraphyPipeline(ink_phase=ink_phase, paper_phase=paper_phase, post_phase=post_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "A.RandomRotate90(p=0.3),\n",
    "A.HorizontalFlip(p=0.3),\n",
    "A.VerticalFlip(p=0.3), \n",
    "A.GaussNoise(p=0.3),\n",
    "A.OneOf([A.MotionBlur(p=.2), A.MedianBlur(blur_limit=3, p=0.1), A.Blur(blur_limit=3, p=0.1),], p=0.3),\n",
    "A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2, border_mode=cv2.BORDER_CONSTANT, value=[255, 255, 255]),\n",
    "A.OneOf([A.OpticalDistortion(p=0.3), A.GridDistortion(p=.1), A.PiecewiseAffine(p=0.3), ], p=0.2),\n",
    "A.OneOf([A.CLAHE(clip_limit=2), A.Sharpen(), A.Emboss(),], p=0.3),\n",
    "A.RandomBrightnessContrast(p=0.3),\n",
    "A.HueSaturationValue(p=0.3)\n",
    "])\n",
    "# transform = A.Compose([\n",
    "#                 A.Rotate(limit=5, border_mode=cv2.BORDER_CONSTANT),\n",
    "#                 A.HorizontalFlip(p=0.3),\n",
    "#                 A.VerticalFlip(p=0.3),  \n",
    "#                 A.RandomRotate90(p=0.3),  \n",
    "#                 A.Blur(blur_limit=4, p=0.3),  \n",
    "#                 A.OpticalDistortion(p=0.3),  \n",
    "#                 A.GridDistortion(p=0.3),  \n",
    "#                 A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=20, val_shift_limit=10, p=0.3), \n",
    "#                 A.RandomBrightnessContrast(p=0.2),\n",
    "#                 A.ShiftScaleRotate(shift_limit=(0.3), scale_limit=(0.3), border_mode=cv2.BORDER_CONSTANT)\n",
    "#             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_origin=pd.read_csv(\"data/train_right.csv\")\n",
    "\n",
    "train_data, valid_data = train_test_split(train_origin, test_size=0.2, stratify=train_origin['target'], random_state=624)\n",
    "valid_data, test_data = train_test_split(valid_data, test_size=0.5, stratify=valid_data['target'], random_state=624)\n",
    "\n",
    "print(len(train_data), len(valid_data), len(test_data))\n",
    "\n",
    "train_data.reset_index(drop=True,inplace=True)\n",
    "valid_data.reset_index(drop=True,inplace=True)\n",
    "test_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=[train_data, valid_data,test_data]\n",
    "prefix=['train','valid','test']\n",
    "num= [[30,10],[15,5],[15,5]]   # [N_Albumnetation, N_Augraphy]\n",
    "\n",
    "for i in range(len(dataframe)):\n",
    "    print(f\"{prefix[i]} Augmentation start\")\n",
    "    print(\"#\"*30)\n",
    "    \n",
    "    origin_img_path='data/train/' # 원래 이미지 폴더\n",
    "    origin_csv=dataframe[i]\n",
    "\n",
    "    aug_img_path=f'data/aug_{prefix[i]}/'\n",
    "    aug_csv_path=f\"data/aug_{prefix[i]}.csv\"\n",
    "\n",
    "    aug_data = augmentation(origin_img_path,origin_csv,aug_img_path,aug_csv_path,transform,pipeline,num[i][0],num[i][1])\n",
    "    #aug_data= makedf(origin_csv,aug_csv_path,num[i][0],num[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload wandb later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bae951753/Document Images Classification/nod23v2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "id_list=['nod23v2g']\n",
    "\n",
    "lbscore_list=[0.9084]\n",
    "#config_list=[\"CosineAnnealingLR\"]\n",
    "#tag_list=['LR_scheduler=CosineAnnealingLR']\n",
    "\n",
    "print(len(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(id_list))):\n",
    "    run= wandb.init(project=\"Document Images Classification\",id=id_list[i],resume='allow')\n",
    "    run.config.update({'LB score':lbscore_list[i]})\n",
    "    #run.config.update({'lr_scheduler':config_list[0]})\n",
    "    #run.tags+=(tag_list[0],)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastdup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://visual-layer.readme.io/docs/analyzing-labeled-images\n",
    "## https://github.com/visual-layer/fastdup?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class와 label이 매핑되어있는 파일 \n",
    "train=pd.read_csv(\"data/train.csv\")\n",
    "train['ID'] = \"data/train/\" + train['ID'].astype(str)\n",
    "train.columns=['filename','label']\n",
    "\n",
    "\n",
    "meta_df=pd.read_csv('data/meta.csv')\n",
    "label2id = dict(zip(meta_df['class_name'], meta_df['target']))\n",
    "id2label = dict(zip(meta_df['target'], meta_df['class_name']))\n",
    "\n",
    "train['label'] = train['label'].map(id2label)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = fastdup.create(input_dir=\"data/train\")\n",
    "fd.run(annotations=train, model_path='clip',d=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.vis.duplicates_gallery()    # create a visual gallery of duplicates\n",
    "fd.vis.outliers_gallery()      # create a visual gallery of anomalies\n",
    "fd.vis.component_gallery()     # create a visualization of connected components\n",
    "fd.vis.stats_gallery()         # create a visualization of images statistics (e.g. blur)\n",
    "fd.vis.similarity_gallery()    # create a gallery of similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar=fd.similarity()\n",
    "report = similar.query(\"label_from != label_to and distance >= 0.95\")\n",
    "report.reset_index(drop=True,inplace=True)\n",
    "report['sorted_from_to'] = report.apply(lambda row: sorted([row['from'], row['to']]), axis=1)\n",
    "\n",
    "# 중복된 행을 제거합니다. \n",
    "report.drop_duplicates(subset='sorted_from_to', keep='first', inplace=True)\n",
    "\n",
    "# 정렬된 from과 to 컬럼 및 중복 제거된 sorted_from_to 컬럼을 삭제합니다.\n",
    "report.drop(columns=[ 'sorted_from_to'], inplace=True)\n",
    "report.reset_index(drop=True,inplace=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# 각 행별로 이미지를 읽어와서 subplot에 표시\n",
    "fig, axs = plt.subplots(nrows=report.shape[0] // 2, ncols=4, figsize=(20, 4*(report.shape[0] // 2)))\n",
    "\n",
    "for i in range(0, report.shape[0], 2):\n",
    "    row1 = report.iloc[i]\n",
    "    row2 = report.iloc[i+1]\n",
    "    \n",
    "    # 홀수 row\n",
    "    filename_from1 = row1['filename_from']\n",
    "    filename_to1 = row1['filename_to']\n",
    "    \n",
    "    label_from1 = row1['label_from']\n",
    "    label_to1 = row1['label_to']\n",
    "    \n",
    "    id_from1= filename_from1[11:-4]\n",
    "    id_to1= filename_to1[11:-4]\n",
    "    \n",
    "    # 짝수row \n",
    "    filename_from2 = row2['filename_from']\n",
    "    filename_to2 = row2['filename_to']\n",
    "\n",
    "    label_from2 = row2['label_from']\n",
    "    label_to2 = row2['label_to']\n",
    "    \n",
    "    id_from2= filename_from2[11:-4]\n",
    "    id_to2= filename_to2[11:-4]\n",
    "    \n",
    "    image_from1 = Image.open(filename_from1)\n",
    "    image_to1 = Image.open(filename_to1)\n",
    "    image_from2 = Image.open(filename_from2)\n",
    "    image_to2 = Image.open(filename_to2)\n",
    "    \n",
    "    axs[i // 2, 0].imshow(image_from1)\n",
    "    axs[i // 2, 0].set_title(f\"Label: {label_from1} \\n id: {id_from1}\")\n",
    "    axs[i // 2, 0].axis('off')\n",
    "    \n",
    "    axs[i // 2, 1].imshow(image_to1)\n",
    "    axs[i // 2, 1].set_title(f\"Label: {label_to1} \\n id: {id_to1}\")\n",
    "    axs[i // 2, 1].axis('off')\n",
    "    \n",
    "    axs[i // 2, 2].imshow(image_from2)\n",
    "    axs[i // 2, 2].set_title(f\"Label: {label_from2}\\n id: {id_from2}\")\n",
    "    axs[i // 2, 2].axis('off')\n",
    "    \n",
    "    axs[i // 2, 3].imshow(image_to2)\n",
    "    axs[i // 2, 3].set_title(f\"Label: {label_to2}\\n id: {id_to2}\")\n",
    "    axs[i // 2, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"data/train.csv\")\n",
    "meta=pd.read_csv('data/meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복->라벨링 오류인걸 없앰\n",
    "train_right = train[~train['ID'].isin(['aec62dced7af97cd.jpg', 'c5182ab809478f12.jpg', '1ec14a14bbe633db.jpg'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오류 아닌데 구분하기 어려운거 \n",
    "train_right = train_right[~train_right['ID'].isin(['4a38e395726fbc06.jpg', 'af650bfc45cb3c46.jpg', 'dda2df9797b370e7.jpg','b709b64897d9233f.jpg'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_right[train_right['ID']=='8646f2c3280a4f49.jpg']\n",
    "train_right.loc[train_right['ID'] == '8646f2c3280a4f49.jpg', 'target'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_right[train_right['ID']=='45f0d2dfc7e47c03.jpg']\n",
    "train_right.loc[train_right['ID'] == '45f0d2dfc7e47c03.jpg', 'target'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_right=train_right.reset_index(drop=True)\n",
    "train_right.to_csv(\"data/train_right.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54380, 3666, 3697)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"data/aug_train.csv\")\n",
    "data2=pd.read_csv(\"data/aug_valid.csv\")\n",
    "data3=pd.read_csv(\"data/aug_test.csv\")\n",
    "\n",
    "len(data),len(data2),len(data3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
