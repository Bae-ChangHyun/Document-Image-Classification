{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"OliaDaX_lwou"},"source":["# **ğŸ“„ Document type classification baseline code**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9396,"status":"ok","timestamp":1700314592802,"user":{"displayName":"Ynot(ì†¡ì›í˜¸)","userId":"16271863862696372773"},"user_tz":-540},"id":"3BaoIkv5Xwa0"},"outputs":[],"source":["import os\n","import time\n","import pandas as pd\n","import numpy as np\n","import copy\n","import wandb\n","from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, confusion_matrix\n","\n","import timm\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.datasets import ImageFolder\n","from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n","import random\n","import torch.backends.cudnn as cudnn\n","from focal_loss.focal_loss import FocalLoss # https://github.com/mathiaszinnen/focal_loss_torch\n","\n","import cv2\n","from PIL import Image\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","# pip uninstall charset-normalizer\n","# pip install charset-normalizer\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ì‹œë“œ ê³ ì •\n","def random_seed(seed_num):\n","    torch.manual_seed(seed_num)\n","    torch.cuda.manual_seed(seed_num)\n","    torch.cuda.manual_seed_all(seed_num)\n","    np.random.seed(seed_num)\n","    cudnn.benchmark = False\n","    cudnn.deterministic = True\n","    random.seed(seed_num)\n","random_seed(624)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# classì™€ labelì´ ë§¤í•‘ë˜ì–´ìˆëŠ” íŒŒì¼ \n","meta_df = pd.read_csv('data/meta.csv')\n","label2id = dict(zip(meta_df['class_name'], meta_df['target']))\n","id2label = dict(zip(meta_df['target'], meta_df['class_name']))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1700314772722,"user":{"displayName":"Ynot(ì†¡ì›í˜¸)","userId":"16271863862696372773"},"user_tz":-540},"id":"Hyl8oAy6TZAu"},"outputs":[],"source":["# ì»¤ìŠ¤í…€ ë°ì´í„° ì…‹\n","class ImageDataset(Dataset):\n","    def __init__(self, csv, path, transform=None):\n","        self.df = pd.read_csv(csv).values\n","        self.path = path\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        name, target = self.df[idx]\n","        img = np.array(Image.open(os.path.join(self.path, name)))\n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","        return img, target,name"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# https://geunuk.tistory.com/456\n","def MixUp(input, target, alpha=1.0):\n","    if alpha > 0:\n","        lambda_ = np.random.beta(alpha, alpha)\n","    else:\n","        lambda_ = 1\n"," \n","    batch_size = input.size(0)\n","    index = torch.randperm(batch_size)\n","    \n","    mixed_input = lambda_ * input + (1 - lambda_) * input[index, :]    \n","    labels_a, labels_b = target, target[index]\n"," \n","    return mixed_input, labels_a, labels_b, lambda_\n","\n","def MixUpLoss(criterion, pred, labels_a, labels_b, lambda_):\n","    return lambda_ * criterion(pred, labels_a) + (1 - lambda_) * criterion(pred, labels_b)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# DataLoader ì •ì˜\n","def dataset(AUG_BOOL,trn_transform,tst_transform):\n","    \n","    # ê¸°ì¡´ ì´ë¯¸ì§€ í˜¹ì€ ì¦ê°•ëœ ì´ë¯¸ì§€\n","    if(AUG_BOOL):train_img_file=\"data/aug_train.csv\"\n","    else: train_img_file=\"data/train.csv\"\n","\n","    origin_train_dataset = ImageDataset(\n","        \"data/train.csv\",\n","        \"data/train/\",\n","        transform=trn_transform\n","    )\n","    trn_dataset = ImageDataset(\n","        train_img_file,  \n","        \"data/aug_train/\",\n","        transform=trn_transform\n","    )\n","    val_dataset = ImageDataset(\n","        \"data/aug_valid.csv\",\n","        \"data/aug_valid/\",\n","        transform=trn_transform\n","    )\n","    tst_dataset = ImageDataset(\n","        \"data/aug_test.csv\",\n","        \"data/aug_test/\",\n","        transform=trn_transform\n","    )\n","    origin_tst_dataset = ImageDataset(\n","        \"data/sample_submission.csv\",\n","        \"data/test/\",\n","        transform=tst_transform\n","    )\n","    \n","    return origin_train_dataset,trn_dataset,val_dataset,tst_dataset,origin_tst_dataset\n","\n","# íŒŒë¼ë¯¸í„°ì— ë”°ë¥¸ ë°ì´í„° ë¡œë”\n","def loader(batch_size,origin_train_dataset,trn_dataset,val_dataset,tst_dataset,origin_tst_dataset):\n","    origin_train_loader = DataLoader(\n","        origin_train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=0,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","    train_loader = DataLoader(\n","        trn_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=0,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","    valid_loader = DataLoader(\n","        val_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=0,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","    test_loader = DataLoader(\n","        tst_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=0,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","    origin_test_loader = DataLoader(\n","        origin_tst_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=0,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","    \n","    return origin_train_loader,train_loader,valid_loader,test_loader,origin_test_loader\n","\n","# ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆì— ë”°ë¥¸ Transform (ê° ëª¨ë¸ë³„ input ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆì™€ ì •ê·œí™”)\n","def image_trasform(image_size,model_mean,model_std):\n","    trn_transform = A.Compose([\n","        A.Resize(height=image_size, width=image_size),\n","        A.Normalize(mean=list(model_mean), std=list(model_std)),\n","        ToTensorV2(),\n","        ])\n","    tst_transform = A.Compose([\n","        A.Resize(height=image_size, width=image_size),\n","        A.Normalize(mean=list(model_mean), std=list(model_std)),\n","        ToTensorV2(),\n","    ])\n","    \n","    return trn_transform,tst_transform"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1700315066028,"user":{"displayName":"Ynot(ì†¡ì›í˜¸)","userId":"16271863862696372773"},"user_tz":-540},"id":"kTECBJfVTbdl"},"outputs":[],"source":["# training, evaluation, training_loop ì½”ë“œ\n","def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, w_config):\n","\n","  model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •\n","  train_loss = 0.0\n","  train_accuracy = 0\n","  all_labels = []\n","  all_predicted = []\n"," \n","  tbar = tqdm(dataloader)\n","  for idx,(images, labels, names) in enumerate(tbar):\n","      images = images.to(device)\n","      labels = labels.to(device)\n","      \n","      # Mixup ì ìš© ë°°ì¹˜ê°€ 3ìœ¼ë¡œ ë‚˜ëˆ ë–¨ì–´ì§ˆ ë–„ ë§ˆë‹¤ ì‹¤í–‰\n","      if (idx + 1) % 3 == 0:\n","          images, labels_a, labels_b, lambda_ = MixUp(images, labels)\n","          outputs = model(images)\n","          if isinstance(outputs, torch.Tensor): outputs = outputs\n","          else: outputs = outputs.logits\n","          loss = MixUpLoss(nn.CrossEntropyLoss(), pred=outputs, labels_a=labels_a, labels_b=labels_b, lambda_=lambda_)\n","      else:                    \n","          outputs = model(images)\n","          if isinstance(outputs, torch.Tensor): outputs = outputs\n","          else: outputs = outputs.logits\n","          if(w_config.loss_f == 'Focal'):loss = criterion(m(outputs), labels) # focal loss\n","          else:loss = criterion(outputs, labels) # corss entropy loss\n","  \n","      # ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n"," \n","      # ì†ì‹¤ê³¼ ì •í™•ë„ ê³„ì‚°\n","      train_loss += loss.item()\n","      \n","      # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","      # _ëŠ” ê°€ì¥ ë†’ì€ í´ë˜ìŠ¤ í™•ë¥ ê°’, predictedëŠ” ê°€ì¥ ë†’ì€ í´ë˜ìŠ¤\n","      _, predicted = torch.max(outputs, 1)\n","      train_accuracy += (predicted == labels).sum().item()\n","      \n","      all_labels.extend(labels.cpu().numpy())\n","      all_predicted.extend(predicted.cpu().numpy())\n"," \n","      tbar.set_description(f\"Epoch [{epoch+1}/{w_config.epochs}], Train Loss: {loss.item():.4f}\")\n"," \n","  # ì—í­ë³„ í•™ìŠµ ê²°ê³¼ ì¶œë ¥\n","  train_loss = train_loss / len(dataloader)\n","  train_accuracy = train_accuracy / len(train_dataset)\n","  precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predicted, average='macro')\n"," \n","  return model, train_loss, train_accuracy, f1\n"," \n","def evaluation(model, dataloader, val_dataset, criterion, device, epoch, w_config):\n","  model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n","  valid_loss = 0.0\n","  valid_accuracy = 0\n","  all_labels = []\n","  all_predicted = []\n"," \n","  with torch.no_grad(): # modelì˜ ì—…ë°ì´íŠ¸ ë§‰ê¸°\n","      tbar = tqdm(dataloader)\n","      for images, labels, names in tbar:\n","          images = images.to(device)\n","          labels = labels.to(device)\n"," \n","          # ìˆœì „íŒŒ\n","          outputs = model(images)\n","          # timmì—ì„œ ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ê³¼ automodelì—ì„œ ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ì˜ output í˜•íƒœê°€ ë‹¤ë¦„\n","          if isinstance(outputs, torch.Tensor): outputs = outputs\n","          else: outputs = outputs.logits\n","          \n","          if(w_config.loss_f == 'Focal'):loss = criterion(m(outputs), labels) # focal loss\n","          else:loss = criterion(outputs, labels) # corss entropy loss\n"," \n","          # ì†ì‹¤ê³¼ ì •í™•ë„ ê³„ì‚°\n","          valid_loss += loss.item()\n","          # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","          _, predicted = torch.max(outputs, 1)\n","          valid_accuracy += (predicted == labels).sum().item()\n","          \n","          all_labels.extend(labels.cpu().numpy())\n","          all_predicted.extend(predicted.cpu().numpy())\n"," \n","          tbar.set_description(f\"Epoch [{epoch+1}/{w_config.epochs}], Valid Loss: {loss.item():.4f}\")\n","          \n","  # í‰ê°€ì§€ìˆ˜\n","  valid_loss = valid_loss / len(dataloader)\n","  valid_accuracy = valid_accuracy / len(val_dataset)\n","  precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predicted, average='macro') # zero_division=1\n"," \n","  return model, valid_loss, valid_accuracy, f1\n"," \n","def training_loop(model, train_loader,valid_loader,train_dataset, val_dataset, criterion, optimizer, scheduler, device, patience, sweep):\n","  \n","    best_valid_loss = float('inf')  # ê°€ì¥ ì¢‹ì€ validation lossë¥¼ ì €ì¥\n","    early_stop_counter = 0  # ì¹´ìš´í„°\n","    valid_max_accuracy = -1\n","    valid_max_f1 = -1\n","    \n","    # wandb ì„¤ì •    \n","    w_config=wandb.config\n","\n","    for epoch in range(w_config.epochs):\n","        model, train_loss, train_accuracy,train_f1 = training(model, train_loader, train_dataset, criterion, optimizer, device, epoch, w_config)\n","        model, valid_loss, valid_accuracy,valid_f1 = evaluation(model, valid_loader, val_dataset, criterion, device, epoch, w_config)\n","        \n","        # wandb ì„¤ì •\n","        # wanb logë  íŒŒë¼ë¯¸í„° ì„¤ì •\n","        monitoring_value = {\n","                            'train_loss': train_loss, 'train_accuracy': train_accuracy, 'train_f1': train_f1, \n","                            'valid_loss': valid_loss, 'valid_accuracy': valid_accuracy, 'valid_f1': valid_f1,\n","                           }\n","        \n","        # ì„¤ì •í•´ë†“ì€ lr_schedulerì— í•´ë‹¹í•˜ëŠ” scheduler ì ìš©\n","        if(w_config.lr_scheduler=='CosineAnnealingLR'):\n","          scheduler.step()\n","          monitoring_value['lr']=scheduler.get_last_lr()[0]\n","        elif(w_config.lr_scheduler=='ReduceLROnPlateau'):\n","          scheduler.step(valid_loss) # ReduceLROnPlateauëŠ” ì•ˆì— ëª¨ë‹ˆí„°ë§í•  valueë¥¼ ë„£ì–´ì¤˜ì•¼í•¨. ì´ì „ì— schedulerì„ ì„ ì–¸í• ë•Œ min,maxë„. \n","          monitoring_value['lr']= optimizer.param_groups[0]['lr'] # ReduceLROnPlateauëŠ” .get_last_lr()[0]ì„ ì§€ì›í•˜ì§€ ì•ŠìŒ \n","        else:monitoring_value['lr']=w_config.learning_rate\n","        \n","        # wandb ì„¤ì •\n","        # epochë³„ë¡œ ê¸°ë¡\n","        wandb.log(monitoring_value, step=epoch) \n"," \n","        if valid_accuracy > valid_max_accuracy:  valid_max_accuracy = valid_accuracy\n","        if valid_f1 > valid_max_f1: valid_max_f1 = valid_f1\n"," \n","        \n","        if valid_loss < best_valid_loss: # validation lossê°€ ê°ì†Œí•˜ë©´ ëª¨ë¸ ì €ì¥ ë° ì¹´ìš´í„° ë¦¬ì…‹\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), f\"{MODEL_PATH}/{EXP_NAME}.pt\")\n","            early_stop_counter = 0\n","        else: early_stop_counter += 1 # validation lossê°€ ì¦ê°€í•˜ê±°ë‚˜ ê°™ìœ¼ë©´ ì¹´ìš´í„° ì¦ê°€\n"," \n","        print(f\"Epoch [{epoch + 1}/{w_config.epochs}], Train Accuracy: {train_accuracy:.4f}, Train Loss: {train_loss:.4f},  Train macro F1: {train_f1:.4f} \")\n","        print(f\"Epoch [{epoch + 1}/{w_config.epochs}], Valid Accuracy: {valid_accuracy:.4f}, Valid Loss: {valid_loss:.4f},  Valid macro F1: {valid_f1:.4f} \")\n","        print(\"#\"*70)\n"," \n","        # earlystopping\n","        if early_stop_counter >= patience:\n","            print(\"Early stopping\")\n","            break\n","          \n","    # wandb ì„¤ì •\n","    # wandb sweepì„ ì‚¬ìš©í•˜ë ¤ë©´ returnê°’ì´ ì—†ì–´ì•¼ í•¨      \n","    if(sweep==False):\n","      return model\n","\n","def inference(model,model_path,device,test_loader,tst_dataset,testmode=0,save=False):\n","  model.load_state_dict(torch.load(model_path)) # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n","  model = model.to(device)\n","  model.eval()\n","  \n","  # wandb ì„¤ì •\n","  # wandbì— ëª¨ë¸ íŒŒì¼ ì—…ë¡œë“œ ìœ ë¬´\n","  if(save):\n","    artifact = wandb.Artifact('model', type='model')\n","    artifact.add_file(model_path)\n","    wandb.log_artifact(artifact)\n","  \n","  total_labels = []\n","  total_preds = []\n","  image_names = []\n","  with torch.no_grad():\n","      for images, labels,names in tqdm(test_loader):\n","          images = images.to(device)\n","          labels = labels.to(device)\n","  \n","          outputs = model(images)\n","          if isinstance(outputs, torch.Tensor): outputs = outputs\n","          else: outputs = outputs.logits\n","          _, predicted = torch.max(outputs.data, 1)\n","  \n","          total_preds.extend(predicted.detach().cpu().tolist())\n","          total_labels.extend(labels.tolist())\n","          image_names.extend(names)\n","          \n","  total_preds = np.array(total_preds)\n","  total_labels = np.array(total_labels)\n","  image_names = np.array(image_names)\n","  total_acc = accuracy_score(total_labels, total_preds) \n","  \n","  precision, recall, f1, _ = precision_recall_fscore_support(total_labels, total_preds, average='macro')\n","  \n","  # sample testìš© -> í•™ìŠµí•˜ì§€ ì•Šì€ ë°ì´í„°ì…‹ ì¶”ë¡  ê²°ê³¼ ì‹œê°í™” \n","  if(testmode==False):\n","    # wandb ì„¤ì •\n","    wandb.summary.update({'test_size':len(tst_dataset),'test_accuracy': total_acc, 'test_fl': f1})\n","    wandb.log({'Test accuracy': wandb.Histogram(total_acc)})\n","    wandb.log({'Test fl_macro': wandb.Histogram(f1)})\n","\n","    print(\"Test model accuracy : \",total_acc) \n","    print(\"Test model macro f1 : \",f1) \n","  \n","  # ìµœì¢… ì¶”ë¡  ê²°ê³¼ë¥¼ ì œì¶œí˜•íƒœë¡œ ë§Œë“¤ê¸° ìœ„í•œ ì½”ë“œ \n","  meta_df=pd.read_csv('data/meta.csv')\n","  id2label = dict(zip(meta_df['target'], meta_df['class_name']))\n","  \n","  result_df = pd.DataFrame({'ID': image_names,'target': total_labels,'pred': total_preds})\n","  result_df['target'] = result_df['target'].map(id2label)\n","  result_df['pred'] = result_df['pred'].map(id2label)\n","  \n","     # testì¼ ê²½ìš° x\n","  if(testmode):result_df.drop(['target'],axis=1,inplace=True)\n","  # validì¼ ê²½ìš°, í‹€ë¦° ì´ë¯¸ì§€ë¥¼ wandbì—ì„œ í™•ì¸ ê°€ëŠ¥\n","  else:\n","    wrong_result=result_df[result_df['target']!=result_df['pred']]\n","    wrong_result.reset_index(drop=True,inplace=True)\n","    # wandbì— ìµœëŒ€ë¡œ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ ê°œìˆ˜ëŠ” 108ì¥ ì´ ì´ìƒì´ ë„˜ì–´ê°€ë©´ error !!\n","    random_indices = random.sample(range(len(wrong_result)), 108)\n","    images_data = []\n","\n","    for idx in random_indices:\n","        row = wrong_result.iloc[idx]\n","        image_id = row['ID']\n","        target = row['target']\n","        pred = row['pred']\n","\n","        image_path = f\"data/aug_test/{image_id}\"\n","        image = Image.open(image_path)\n","\n","        # ì´ë¯¸ì§€ ë°ì´í„°ì™€ í•´ë‹¹ ì˜ˆì¸¡ ë° íƒ€ê²Ÿì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n","        images_data.append((image, pred, target))\n","  \n","    wandb.log({'Wrong Pred': [wandb.Image(img, caption=f\"Pred: {pred}, Target: {target}\") for img, pred, target in images_data]})\n","    wandb.sklearn.plot_confusion_matrix(result_df['target'], result_df['pred'])\n","    \n","\n","  # inference ê²°ê³¼ ë°˜í™˜\n","  return result_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## timmë§ê³  ëª¨ë¸ ë¶ˆëŸ¬ì˜¬ ë–„ ì‚¬ìš©\n","# MODEL_NAME= 'microsoft/dit-base-finetuned-rvlcdip'\n","# image_processor  = AutoImageProcessor.from_pretrained(MODEL_NAME)\n","# model = AutoModelForImageClassification.from_pretrained(MODEL_NAME, \n","#     label2id=label2id,\n","#     id2label=id2label,\n","#     ignore_mismatched_sizes = True, \n","#     num_labels=17\n","# ).to(device)\n","# if \"height\" in image_processor.size:\n","#     IMG_SIZE = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n","#     crop_size = size\n","#     max_size = None\n","# elif \"shortest_edge\" in image_processor.size:\n","#     IMG_SIZE = image_processor.size[\"shortest_edge\"]\n","#     crop_size = (size, size)\n","#     max_size = image_processor.size.get(\"longest_edge\")"]},{"cell_type":"markdown","metadata":{},"source":["# Setting"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# wanb ì„¤ì • --> í”„ë¡œì íŠ¸ëª… ì •í™•í•˜ê²Œ ì…ë ¥\n","PROJECT_NAME='Docs Image Classifications'\n","\n","# ìë™í™”í•  ëª¨ë¸ list \n","models = ['resnet50']\n","# resnet50, resnet101.a1_in1k, resnet34, vgg16, beitv2_base_patch16_224.in1k_ft_in22k_in1k, swin_small_patch4_window7_224.ms_in22k_ft_in1k, convnext_small.fb_in22k\n","\n","# ì‹¤í—˜í•  batch size ë¦¬ìŠ¤íŠ¸ # 64,128,256,512\n","batch_list=[64,128,256] \n","\n","# ì‹¤í—˜í•  image size ë¦¬ìŠ¤íŠ¸ # 224,256\n","image_size_list=[224,384] # 224\n","\n","lr_scheduler_list=['X','ReduceLROnPlateau','CosineAnnealingLR'] # 'X',\n","\n","loss_list=['CE','Focal']\n","\n","CONFIG={\n","    \"weight_decay\":False,  # 1e-3\n","    \"aug_train\":True,      # False\n","    \"learning_rate\": 1e-4,\n","    \"epochs\": 15,\n","    'patience':5,\n","    }\n","\n","# ëª¨ë¸ì„ wandbì— ì €ì¥í• ì§€ ë§ì§€\n","SAVE_MODEL=False\n","\n","MODEL_PATH = \"final_model\"\n","SUB_PATH = \"final_submission\"\n","\n","suffix=\",focal_loss\""]},{"cell_type":"markdown","metadata":{},"source":["# Train & Inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for model_s in models:\n","    for image_s in image_size_list:\n","        for batch_s in batch_list:\n","            for lr_scheduler_s in lr_scheduler_list:\n","                for loss_s in loss_list:\n","                    print(\"#\"*100)\n","                    print(f\"Model:{model_s},Image_size:{image_s},Batch_size:{batch_s},Sheduler:{lr_scheduler_s}\")  \n","                    \n","                    # wandb ì„¤ì • -> config íŒŒì¼ ì´ ì„¤ì •ì„ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ ëŒì•„ê°\n","                    temp={ \"model\":model_s, \"image_size\":image_s,\"batch_size\":batch_s,\"lr_scheduler\":lr_scheduler_s,'loss_f':loss_s}\n","                    config = copy.deepcopy(CONFIG)\n","                    config.update(temp)\n","                \n","                    # ptëª¨ë¸ ì €ì¥ ì´ë¦„ & wandb run ì´ë¦„ & ì¶”ë¡  ê²°ê³¼ ì´ë¦„ \n","                    EXP_NAME = f\"{config['model']}(is={config['image_size']},bs={config['batch_size']},lr_s={config['lr_scheduler']},loss_f={config['loss_f']}{suffix})\"  \n","                    EXP_NAME=EXP_NAME.replace(\"/\",'_').replace('.','_')\n","                    \n","                    # wandb ì„¤ì • -> tag ì„¤ì • \n","                    TAG=[f\"MODEL={config['model']}\",f\"IMG={config['image_size']}\",f\"BATCH={config['batch_size']}\",f\"LR={config['learning_rate']}\",f\"L2={config['weight_decay']}\",f\"LR_scheduler={config['lr_scheduler']}\",f\"loss_f={config['loss_f']}\"]\n","                    \n","                    # wandb ì„¤ì • -> í”„ë¡œì íŠ¸ ì‹œì‘\n","                    wandb.init(project=PROJECT_NAME,name=EXP_NAME,tags=TAG,config=config)\n","\n","                    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n","                    num_workers = 0\n","                    \n","                    # timmì—ì„œ ì§€ì •ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜´ \n","                    model = timm.create_model(config['model'],pretrained=True,num_classes=17).to(device)\n","                    model_config= timm.data.resolve_model_data_config(model)\n","                    \n","                    wandb.config.update({'mean':model_config['mean'],'std':model_config['std']})\n","                    # timmì—ì„œ ì§€ì •ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜´ \n","\n","                    # for para in model.parameters(): # ëª¨ë“  layer freeze í•˜ê¸°\n","                    #     para.requires_grad = False\n","                    # for para in model.fc.parameters(): # fc layer ë§Œ í•™ìŠµí•˜ê¸°\n","                    #     para.requires_grad = True\n","                    \n","                    # batchsizeì™€ image sizeì— ë”°ë¼ transform, dataset, loaderì„ ë¶ˆëŸ¬ì˜´ \n","                    trn_transform,tst_transform=image_trasform(config['image_size'],model_config['mean'],model_config['std'])\n","                    origin_train_dataset,trn_dataset,val_dataset,tst_dataset,origin_tst_dataset = dataset(config['aug_train'],trn_transform,tst_transform)\n","                    origin_train_loader,train_loader,valid_loader,test_loader,origin_test_loader = loader(config['batch_size'],origin_train_dataset,trn_dataset,val_dataset,tst_dataset,origin_tst_dataset)\n","                    \n","                    # ê¸°ë³¸ì€ cross entropy -> mixupí•  ê²½ìš° trainingì—ì„œ ë”°ë¡œ ì ìš©\n","                    \n","                    if(config['loss_f']=='CE'):\n","                        loss_fn=nn.CrossEntropyLoss()\n","                    else:\n","                        loss_fn = FocalLoss(gamma=1.5)\n","                        m = torch.nn.Softmax(dim=-1)\n","\n","                    # Weight decay ì ìš©\n","                    if(config['weight_decay']): optimizer = Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay']) \n","                    else: optimizer = Adam(model.parameters(), lr=config['learning_rate'])\n","                    \n","                    # learning rate scheduler ì ìš© -> Cosine Annealing / ReduceLROnPlateau / X\n","                    if(config['lr_scheduler']=='CosineAnnealingLR'): scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n","                    elif(config['lr_scheduler']=='ReduceLROnPlateau'):scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n","                    else: scheduler = False\n","                    \n","                    # train setì—ì„œ ë¶„ë¦¬í•œ train, valid set\n","                    model = training_loop(model, train_loader, valid_loader, trn_dataset, val_dataset, loss_fn, optimizer, scheduler, device, config['patience'], sweep=False)\n","                    \n","                    # í•™ìŠµí•˜ì§€ ì•Šì€ í‰ê°€ìš© sample test\n","                    result_df=inference(model,f\"{MODEL_PATH}/{EXP_NAME}.pt\",device,test_loader,tst_dataset,testmode=False,save=False)\n","                    \n","                    # ì‹¤ì œ test set --> save =True ì¼ê²½ìš° wandbì— ëª¨ë¸ ì €ì¥.\n","                    submission=inference(model,f\"{MODEL_PATH}/{EXP_NAME}.pt\",device,origin_test_loader,origin_tst_dataset,testmode=True,save=SAVE_MODEL)\n","                    \n","                    sample_submission=pd.read_csv('data/sample_submission.csv')\n","                    submission = sample_submission.merge(submission, on='ID', how='left')\n","                    submission.drop(['target'],axis=1,inplace=True)\n","                    submission.columns=['ID','target']\n","                    submission['target'] = submission['target'].map(label2id)\n","                    submission.to_csv(f\"{SUB_PATH}/{EXP_NAME}.csv\",index=False)\n","                    wandb.log({\"csv_data\": submission})\n","                    wandb.finish()\n","                    random_seed(624)\n","                    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["break"]},{"cell_type":"markdown","metadata":{},"source":["# Ensemble"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆì— ë”°ë¥¸ Transform --> ì¶”í›„ì— ì •ê·œí™”ë„ ê° ëª¨ë¸ë³„ë¡œ ì •ì˜\n","## ì˜ì²œë‹˜ ì œëª© ì˜ë¼ ë¶™ì´ëŠ” ê²½ìš°\n","# def tta_trasform(image_size,model_mean,model_std):\n","\n","#     tst_transform = A.Compose([\n","#         A.LongestMaxSize(max_size=640, interpolation=cv2.INTER_CUBIC),\n","#         A.PadIfNeeded(min_height=640, min_width=640, border_mode=cv2.BORDER_CONSTANT, value=[255, 255, 255]),\n","#         A.ShiftScaleRotate(shift_limit_x=0.2, shift_limit_y=(0.0, 0.1), scale_limit=0.2, rotate_limit=0, p=0.7, border_mode=cv2.BORDER_CONSTANT, value=[255, 255, 255]),\n","#         A.Crop (x_min=128, y_min=0, x_max=128+384, y_max=384, p=1.0),\n","#         A.Normalize(mean=list(model_mean), std=list(model_std)),\n","#         ToTensorV2(),\n","#     ])\n","    \n","#     return tst_transform\n","\n","def tta_trasform(image_size,model_mean,model_std):\n","\n","    tst_transform = A.Compose([\n","        A.Resize(height=image_size, width=image_size),\n","        A.Normalize(mean=list(model_mean), std=list(model_std)),\n","        ToTensorV2(),\n","    ])\n","    \n","    return tst_transform"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def tta_dataset(AUG_BOOL,tst_transform):\n","\n","    origin_tst_dataset = ImageDataset(\n","        \"data/sample_submission.csv\",\n","        #\"data/test_rot_catformer01/\",\n","        \"data/test/\",\n","        transform=tst_transform\n","    )\n","    \n","    return origin_tst_dataset\n","\n","def tta_loader(batch_size,origin_tst_dataset):\n","    \n","    origin_test_loader = DataLoader(\n","        origin_tst_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=0,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","    \n","    return origin_test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df=pd.read_csv('data/meta_kr.csv',encoding='cp949')\n","id2label = dict(zip(meta_df['target'], meta_df['kr']))\n","label2id = dict(zip(meta_df['kr'], meta_df['target']))\n","\n","sample_submission=pd.read_csv('data/sample_submission.csv')\n","sample_submission.drop(['target'],axis=1,inplace=True)\n","\n","image_size=384\n","batch_size=64\n","\n","tst_transform=tta_trasform(image_size,(0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n","origin_tst_dataset = tta_dataset(True,tst_transform)\n","origin_test_loader = tta_loader(batch_size,origin_tst_dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   "]},{"cell_type":"markdown","metadata":{},"source":["## TTA: Test Time Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ttachë¥¼ ì´ìš©í•˜ì—¬ augmentationí•˜ë©´ ëª¨ë“  transform ê²½ìš°ì˜ ìˆ˜ê°€ ì ìš©ë¨.\n","# https://github.com/qubvel/ttach?tab=readme-ov-file\n","\n","import ttach as tta\n","\n","transforms = tta.Compose(\n","    [\n","        tta.HorizontalFlip(),\n","        tta.VerticalFlip(),\n","        #tta.Rotate90(angles = [0, 90, 180]),\n","        #tta.FiveCrops(224, 224),  # ë‹¤ì„¯ ê°€ì§€ ë‹¤ë¥¸ crop ìƒì„±\n","        #tta.Multiply(factors=[0.8, 1, 1.1]),        \n","    ]\n",")\n","\n","## ttaì˜ augmentationì„ í–ˆì„ ë•Œ ì˜ˆì‹œ ì´ë¯¸ì§€\n","# image = np.array(Image.open('data/test/0b8426f6b3d9d4a3.jpg')) / 255\n","# image = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).to(torch.float32)\n","\n","# fig = plt.figure(figsize=(20, 20))\n","# columns = 2\n","# rows = 5\n","\n","# for i, transform in enumerate(transforms):\n","#     image_transformed = transform.augment_image(image)\n","#     image_transformed = np.array(image_transformed.squeeze()).transpose(1, 2, 0)\n","#     fig.add_subplot(rows, columns, i+1)\n","#     plt.imshow(image_transformed)\n","\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def only_inference(model, test_loader, device):\n","    \n","    model.to(device)\n","    model.eval()\n","    probabilities=[]\n","    total_preds = []\n","    image_names = []\n","    with torch.no_grad():\n","        for images, labels, names in tqdm(test_loader):\n","            images = images.to(device)\n","            \n","            outputs = model(images)\n","            probs, predicted = torch.max(outputs.data, 1)\n","\n","            total_preds.extend(predicted.detach().cpu().tolist())\n","            probabilities.extend(probs.detach().cpu().tolist())\n","            image_names.extend(names)\n","            \n","    return image_names,total_preds,probabilities"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#model_name='resnet50'\n","model_name=\"caformer_s18.sail_in22k_ft_in1k_384\"\n","            \n","model = timm.create_model(model_name,pretrained=True,num_classes=17)\n","model_config= timm.data.resolve_model_data_config(model)\n","trn_transform,tst_transform=image_trasform(model_config['input_size'][1],model_config['mean'],model_config['std'])\n","\n","#model_path = 'model/Best_resnet50(is=384,bs=64,LS=Red_f1,Shuffle).pt'\n","model_path = 'model/caformer_s18_sail_in22k_ft_in1k_384_loss_titlecrop02.pth'\n","\n","model.load_state_dict(torch.load(model_path)) \n","\n","# ttachì— ìˆëŠ” classë¡œ wrappí•´ì£¼ë©´, ëª¨ë“  augê²½ìš°ì˜ ìˆ˜ ì¤‘ merge_modeì— ë”°ë¥¸ ê°’ì„ ë°˜í™˜\n","# https://github.com/qubvel/ttach/blob/master/ttach/wrappers.py#L52\n","\n","tta_model = tta.ClassificationTTAWrapper(model, transforms, merge_mode='mean')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ì„ íƒ ëª¨ë¸ tta ì¶”ë¡  ê²°ê³¼\n","image_names,total_preds,probabilities = only_inference(tta_model,origin_test_loader,device)\n","result_tta = pd.DataFrame({'ID': image_names,'target': total_preds,'probs':probabilities})\n","\n","# ì„ íƒ ëª¨ë¸ ê¸°ë³¸ ì¶”ë¡  ê²°ê³¼\n","image_names,total_preds,probabilities = only_inference(model,origin_test_loader,device)\n","result_best = pd.DataFrame({'ID': image_names,'target': total_preds,'probs':probabilities})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tta_result = sample_submission.merge(result_tta, on='ID', how='left')\n","tta_result.columns=['ID','tta_target','tta_probs']\n","\n","tta_result = tta_result.merge(result_best, on='ID', how='left')\n","tta_result.columns=['ID','tta_target','tta_probs','bestscore_target','bestscore_probs']\n","tta_result['tta_target']=tta_result['tta_target'].map(id2label)\n","tta_result['bestscore_target']=tta_result['bestscore_target'].map(id2label)\n","tta_result.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ë‘ ëª¨ë¸(ttaì ìš©,ë¯¸ì ìš©) ê²°ê³¼ì˜ í´ë˜ìŠ¤ì˜ í™•ë¥ ê°’ì„ ë¹„êµí•˜ì—¬ ë” ë†’ì€ í´ë˜ìŠ¤ì˜ í™•ë¥ ê°’ì„ ì„ ì •\n","tta_result['final_target'] = tta_result.apply(lambda x: x['tta_target'] if x['tta_probs'] > x['bestscore_probs'] else x['bestscore_target'], axis=1)\n","tta_result[tta_result['tta_target']!=tta_result['bestscore_target']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tta_submission= tta_result[['ID','final_target']]\n","tta_submission.columns=['ID','target']\n","tta_submission['target'] = submission['target'].map(label2id)\n","#submission.to_csv('tta_ì˜ì²œ_cropì œëª©.csv',index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["break"]},{"cell_type":"markdown","metadata":{},"source":["## Weighted soft voting"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load_model(model_path):\n","    print(model_path)\n","    model_path='best_model/'+model_path\n","    if(model_path in [\"best_model/Final_resnet50(is=224,bs=128,LS=Red_f1,Shuffle).pt\",\"best_model/Re_Final_resnet50(is=224,bs=128,LS=Red_f1,Shuffle).pt\"]):\n","        model = timm.create_model('resnet50',pretrained=True,num_classes=17).to(device)\n","    else:\n","        model = timm.create_model('caformer_s18.sail_in22k_ft_in1k_384',num_classes=17).to(device)\n","    \n","    model.load_state_dict(torch.load(model_path)) \n","    model.eval()\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def ensemble_inference(models, weights, test_loader):\n","    predictions = torch.zeros(0, dtype=torch.long).to(device)\n","    image_names = []\n","    probabilities=[]\n","    with torch.no_grad():\n","        for images, labels, names in tqdm(test_loader):\n","            images = images.to(device)\n","            avg_output = torch.zeros(images.size(0), 17).to(device)\n","            \n","            for model, weight in zip(models, weights):\n","                # metaformerì€ íŠ¹ì • ëª¨ë¸ class ì´ë¦„-> inputsize 384 \n","                if model.__class__.__name__ in ['MetaFormer']:\n","                    preprocess = transforms.Compose([\n","                        transforms.Resize((384, 384)),\n","                    ])\n","                    images = preprocess(images)\n","                outputs = model(images)\n","                avg_output += weight * F.softmax(outputs, dim=1)\n","            probs, preds = torch.max(avg_output, 1)\n","            \n","            predictions = torch.cat((predictions, preds), dim=0)\n","            probabilities.extend(probs.detach().cpu().tolist())\n","            image_names.extend(names)\n","            \n","        predictions=predictions.cpu().numpy()\n","            \n","    return predictions,image_names,probabilities"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_paths = [\"Final_resnet50(is=224,bs=128,LS=Red_f1,Shuffle).pt\",'caformer_s18_sail_in22k_ft_in1k_384_loss_titlecrop.pth','caformer_s18_sail_in22k_ft_in1k_384.pth'] \n","models_ = [load_model(path) for path in model_paths]\n","weights = [0.1,0.4,0.4] # ê° ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ \n","\n","## ttaëª¨ë¸ë„ ì¶”ê°€í•  ê²½ìš°\n","#tta_model.eval()\n","#tta_model.to(device)\n","#models_.append(tta_model)\n","#weights.append(0.1)\n","\n","ensemble_predictions,image_names,probabilities = ensemble_inference(models, weights, origin_test_loader)\n","\n","result_weighted = pd.DataFrame({'ID': image_names,'target': ensemble_predictions,'probs':probabilities})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["weight_result = sample_submission.merge(result_tta, on='ID', how='left')\n","weight_result.columns=['ID','weight_target','weight_probs']\n","\n","weight_result = weight_result.merge(result_best, on='ID', how='left')\n","weight_result.columns=['ID','weight_target','weight_probs','bestscore_target','bestscore_probs']\n","weight_result['weight_target'] = weight_result['weight_target'].map(id2label)\n","weight_result['bestscore_target'] = weight_result['bestscore_target'].map(id2label)\n","weight_result.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["weight_result[(weight_result['weight_probs']>weight_result['bestscore_probs']) & (weight_result['weight_target']!=weight_result['bestscore_target'])]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["weight_result['final_target'] = weight_result.apply(lambda x: x['weight_target'] if x['weight_probs'] > x['bestscore_probs'] else x['bestscore_target'], axis=1)\n","weight_result[weight_result['weight_target']!=weight_result['bestscore_target']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["weight_result= weight_result[['ID','final_target']]\n","weight_result.columns=['ID','target']\n","weight_result['target'] = weight_result['target'].map(label2id)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#weight_result.to_csv(\"submission/ì˜ì²œ_ì°½í˜„_weigthed+probs.csv\",index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Hard Voting"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["folder_path = \"best_submission/\"\n","\n","file_list = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n","\n","label_encoder = LabelEncoder()\n","encoded_labels = label_encoder.fit_transform(file_list)\n","\n","label_mapping = dict(zip(encoded_labels, file_list))\n","\n","dfs = []\n","for label, file in label_mapping.items():\n","    file_path = os.path.join(folder_path, file)\n","    df = pd.read_csv(file_path)\n","    df = df.rename(columns={'target': f'target_{label}'})\n","    dfs.append(df)\n","\n","voting_result = pd.concat(dfs, axis=1, join='inner')\n","voting_result = voting_result.loc[:,~voting_result.columns.duplicated()]\n","voting_result.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["voting_result['mode_TARGET'] = voting_result.mode(axis=1)[0]\n","voting_result.iloc[:, 1:] = voting_result.iloc[:, 1:].apply(lambda col: col.map(id2label))\n","voting_result.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["label_mapping"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#diff = voting_result[(voting_result[['target_0', 'target_2', 'target_1','target_3']].values != voting_result['mode_TARGET'].values.reshape(-1, 1)).any(axis=1)]\n","diff = voting_result[(voting_result[['target_3']].values != voting_result['mode_TARGET'].values.reshape(-1, 1)).any(axis=1)]\n","len(diff)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ëª¨ë‘ í•œë²ˆì”© ë‚˜ì™€ì„œ ìµœë¹ˆê°’ì´ ì ìš©ì´ ì•ˆë  ê²½ìš°\n","nan_rows = voting_result[voting_result['mode_TARGET'].isna()]\n","nan_rows"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ê°€ì¥ ë¦¬ë”ë³´ë“œ ìŠ¤ì½”ì–´ê°€ ì¢‹ì€ ê²°ê³¼ê°’ìœ¼ë¡œ ì±„ì›€\n","voting_result.loc[nan_rows.index, 'mode_TARGET'] = nan_rows['target_3']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["submission = voting_result[['ID','mode_TARGET']]\n","submission.columns=['ID','target']\n","submission['target']=submission['target'].map(label2id)\n","submission.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#submission.to_csv(\"ì˜ì²œ096+ì˜ì²œcrop_ttaì°½í˜„+ì˜ˆëŒpred21+09532.csv\",index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
